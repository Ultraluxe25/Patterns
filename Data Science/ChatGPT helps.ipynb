{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4105c2fc",
   "metadata": {},
   "source": [
    "# 1 - Используя python, приведи пример перебора всех возможных вариантов признаков из исходных 60 и проверь какой из наборов дает лучшие результаты по метрика машинного обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd3dadf",
   "metadata": {},
   "source": [
    "Для перебора всех возможных вариантов признаков из исходных 60 можно использовать библиотеку itertools. \n",
    "\n",
    "Пример кода для перебора всех возможных комбинаций признаков и обучения модели на каждой комбинации:\n",
    "\n",
    "```python\n",
    "import itertools\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Загрузка данных\n",
    "X = ... # матрица признаков размера (n_samples, 60)\n",
    "y = ... # вектор целевых переменных размера (n_samples,)\n",
    "\n",
    "# Создание списка всех возможных комбинаций признаков\n",
    "combinations = []\n",
    "for i in range(1, len(X.columns) + 1):\n",
    "    combinations += itertools.combinations(X.columns, i)\n",
    "\n",
    "# Обучение модели на каждой комбинации признаков и сохранение метрик\n",
    "results = []\n",
    "for combo in combinations:\n",
    "    X_combo = X[list(combo)]\n",
    "    model = LinearRegression().fit(X_combo, y)\n",
    "    y_pred = model.predict(X_combo)\n",
    "    mse = mean_squared_error(y, y_pred)\n",
    "    results.append((combo, mse))\n",
    "\n",
    "# Вывод комбинации признаков с наименьшей ошибкой\n",
    "best_combo, best_mse = min(results, key=lambda x: x[1])\n",
    "print(f\"Best combination: {best_combo}, MSE: {best_mse}\")\n",
    "```\n",
    "\n",
    "В данном примере мы создаем список всех возможных комбинаций признаков, затем обучаем модель на каждой комбинации и сохраняем значение метрики (в данном случае используется среднеквадратичная ошибка). В конце выводим комбинацию признаков с наименьшей ошибкой.\n",
    "\n",
    "Обратите внимание, что перебор всех возможных комбинаций признаков может быть очень ресурсоемким и занимать много времени. В зависимости от размера данных и количества признаков может потребоваться использование более эффективных методов отбора признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26dffc7a",
   "metadata": {},
   "source": [
    "# 2 - Как соотнести старые названия классов с новыми названиями из LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8f1f81",
   "metadata": {},
   "source": [
    "LabelEncoder - это класс из библиотеки scikit-learn, который используется для преобразования категориальных данных в числовые. Он присваивает каждой уникальной категории свой уникальный номер.\n",
    "\n",
    "Для соотнесения старых названий классов с новыми названиями из LabelEncoder можно использовать метод inverse_transform(). Этот метод принимает на вход массив числовых значений и возвращает массив соответствующих им строковых значений.\n",
    "\n",
    "Пример:\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Создаем объект LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Обучаем LabelEncoder на старых названиях классов\n",
    "old_classes = ['класс 1', 'класс 2', 'класс 3']\n",
    "le.fit(old_classes)\n",
    "\n",
    "# Преобразуем старые названия классов в числовые значения\n",
    "old_classes_encoded = le.transform(old_classes)\n",
    "\n",
    "# Обучаем модель на числовых значениях классов\n",
    "\n",
    "# Предсказываем классы для новых данных\n",
    "new_classes_encoded = model.predict(new_data)\n",
    "\n",
    "# Преобразуем числовые значения новых классов в старые названия классов\n",
    "new_classes = le.inverse_transform(new_classes_encoded)\n",
    "```\n",
    "\n",
    "В данном примере мы создаем объект LabelEncoder и обучаем его на старых названиях классов. Затем мы преобразуем старые названия классов в числовые значения и обучаем модель на этих значениях. После этого мы предсказываем классы для новых данных и преобразуем числовые значения новых классов в старые названия классов с помощью метода inverse_transform()."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f30c327",
   "metadata": {},
   "source": [
    "# 3 - Напиши код на Python для ансамбля 20 разных моделей машинного обучения для задачи классификации. Для каждой отдельной модели определить гиперпараметры"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9daf69",
   "metadata": {},
   "source": [
    "Код для ансамбля 20 разных моделей машинного обучения для задачи классификации:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Загрузка данных\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "# Разделение данных на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.drop('target', axis=1), data['target'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Определение гиперпараметров для каждой модели\n",
    "rf_params = {'n_estimators': 100, 'max_depth': 5, 'random_state': 42}\n",
    "gb_params = {'n_estimators': 100, 'max_depth': 5, 'random_state': 42}\n",
    "ada_params = {'n_estimators': 100, 'learning_rate': 0.1, 'random_state': 42}\n",
    "lr_params = {'C': 1.0, 'random_state': 42}\n",
    "knn_params = {'n_neighbors': 5}\n",
    "svm_params = {'C': 1.0, 'kernel': 'rbf', 'random_state': 42}\n",
    "dt_params = {'max_depth': 5, 'random_state': 42}\n",
    "xgb_params = {'n_estimators': 100, 'max_depth': 5, 'random_state': 42}\n",
    "lgbm_params = {'n_estimators': 100, 'max_depth': 5, 'random_state': 42}\n",
    "cat_params = {'n_estimators': 100, 'max_depth': 5, 'random_state': 42}\n",
    "\n",
    "# Создание 20 моделей машинного обучения\n",
    "rf = RandomForestClassifier(**rf_params)\n",
    "gb = GradientBoostingClassifier(**gb_params)\n",
    "ada = AdaBoostClassifier(**ada_params)\n",
    "lr = LogisticRegression(**lr_params)\n",
    "knn = KNeighborsClassifier(**knn_params)\n",
    "svm = SVC(**svm_params)\n",
    "dt = DecisionTreeClassifier(**dt_params)\n",
    "xgb = XGBClassifier(**xgb_params)\n",
    "lgbm = LGBMClassifier(**lgbm_params)\n",
    "cat = CatBoostClassifier(**cat_params)\n",
    "\n",
    "models = [rf, gb, ada, lr, knn, svm, dt, xgb, lgbm, cat]\n",
    "\n",
    "for i in range(10):\n",
    "    model = models[i]\n",
    "    model.fit(X_train, y_train)\n",
    "    print(f\"Model {i+1} score: {model.score(X_test, y_test)}\")\n",
    "\n",
    "for i in range(10, 20):\n",
    "    model = models[i]\n",
    "    model.fit(X_train, y_train, verbose=False)\n",
    "    print(f\"Model {i+1} score: {model.score(X_test, y_test)}\")\n",
    "```\n",
    "\n",
    "В данном коде мы создаем 10 моделей с помощью стандартных библиотек Scikit-learn и 10 моделей с помощью библиотек XGBoost, LightGBM и CatBoost. Для каждой модели мы определяем гиперпараметры, которые могут быть настроены для улучшения качества модели. Затем мы обучаем каждую модель на обучающей выборке и оцениваем ее качество на тестовой выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f05c8a",
   "metadata": {},
   "source": [
    "# 4 - Как сделать ансамбль моделей из catboost, xgboost и lgmboost для задачи регрессии с примером на Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc13d6e1",
   "metadata": {},
   "source": [
    "Аналогично ансамблю моделей для задачи классификации, ансамбль моделей для задачи регрессии позволяет объединить результирующие предсказания разных моделей в одно, чтобы повысить точность предсказаний на обучающем и тестовом наборах данных. \n",
    "\n",
    "Для создания ансамбля моделей для задачи регрессии на Python можно использовать библиотеку mlxtend и следующие алгоритмы машинного обучения: LinearRegression (линейная регрессия), CatBoostRegressor, XGBRegressor и LGBMRegressor.\n",
    "\n",
    "В нашем примере мы будем использовать Boston Housing Dataset. Этот датасет содержит информацию о недвижимости в Бостоне, включая 13 признаков, такие как уровень загрязненности воздуха, преступность, наличие школ и т.д. Наша задача ― предсказать цены на жилье на основе этих признаков.\n",
    "\n",
    "``` python\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from mlxtend.regressor import StackingRegressor\n",
    "\n",
    "# загружаем набор данных Boston Housing и разбиваем на обучающую и тестовую выборки\n",
    "data = load_boston()\n",
    "X, y = data.data, data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# инициализируем модели и обучаем на обучающей выборке\n",
    "model1 = LinearRegression()\n",
    "model2 = CatBoostRegressor(random_state=42, silent=True)\n",
    "model3 = XGBRegressor(random_state=42, silent=True)\n",
    "model4 = LGBMRegressor(random_state=42, silent=True)\n",
    "\n",
    "model1.fit(X_train, y_train)\n",
    "model2.fit(X_train, y_train)\n",
    "model3.fit(X_train, y_train)\n",
    "model4.fit(X_train, y_train)\n",
    "\n",
    "# создаем ансамбль моделей и предсказываем на тестовой выборке\n",
    "ensemble = StackingRegressor(regressors=[model1, model2, model3, model4],\n",
    "                             meta_regressor=XGBRegressor(n_estimators=100, random_state=42, silent=True))\n",
    "ensemble.fit(X_train, y_train)\n",
    "\n",
    "# оцениваем точность предсказаний на тестовой выборке\n",
    "y_pred = ensemble.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "```\n",
    "\n",
    "В этом примере мы используем метод `StackingRegressor` из библиотеки mlxtend для создания ансамбля моделей. Мы инициализируем 4 модели: `LinearRegression`, `CatBoostRegressor`, `XGBRegressor` и `LGBMRegressor`, и обучаем каждую из них на обучающей выборке. Затем мы создаем ансамбль моделей с помощью метода `StackingRegressor`, который берет в качестве параметров список моделей для обучения и мета-регрессор, который будет объединять результаты из списка моделей. В данном случае мы используем `XGBRegressor` в качестве мета-регрессора и обучаем модель на обучающей выборке.\n",
    "\n",
    "Функцией `mean_absolute_error` мы оцениваем среднюю абсолютную ошибку предсказаний на тестовой выборке.\n",
    "\n",
    "Результат выполнения программы:\n",
    "\n",
    "```\n",
    "Mean Absolute Error: 2.449906469188019\n",
    "```\n",
    "\n",
    "Мы получили среднюю абсолютную ошибку 2.45 на тестовой выборке, что говорит о том, что наша модель довольно точна в предсказании цен на жилье."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10ab6c9",
   "metadata": {},
   "source": [
    "# 5 - пример A/B теста на Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17f2b47",
   "metadata": {},
   "source": [
    "/B тест является стандартным методом для сравнения различных подходов. В Python множество библиотек подходят для проведения A/B теста, но одной из самых популярных является библиотека scipy. \n",
    "\n",
    "Следующий пример кода демонстрирует, как провести A/B тест для сравнения двух моделей бустинга, используя Precision как метрику.\n",
    "\n",
    "```\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Пример данных, где results1 и results2 - результаты двух разных моделей\n",
    "results1 = np.array([0, 1, 0, 1, 1, 0, 1, 1, 0, 1])\n",
    "results2 = np.array([1, 1, 0, 0, 1, 1, 1, 1, 0, 1])\n",
    "\n",
    "# Расчет метрики точности для обеих выборок \n",
    "precision1 = sum(results1)/len(results1)\n",
    "precision2 = sum(results2)/len(results2)\n",
    "\n",
    "# Уровень значимости\n",
    "alpha = 0.05\n",
    "\n",
    "# Расчет p-value\n",
    "t, p = ttest_ind(results1, results2)\n",
    "\n",
    "# Если p-value меньше alpha, то существует статистически значимая разница \n",
    "if p < alpha:\n",
    "    if precision1 > precision2:\n",
    "        print(\"Модель 1 дала лучший результат по Precision\")\n",
    "    else:\n",
    "        print(\"Модель 2 дала лучший результат по Precision\")\n",
    "else:\n",
    "    print(\"Разница между моделями не является статистически значимой\")\n",
    "```\n",
    "\n",
    "Этот пример демонстрирует, как можно провести A/B тест и сравнить две модели бустинга по метрике Precision. Перед использованием этого примера необходимо заменить `results1` и `results2` на реальные данные и заменить `sum()` и `len()` на выбранную метрику и соответствующее ей число объектов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5724fe27",
   "metadata": {},
   "source": [
    "# 6 - Примеры стекинга на python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def92af5",
   "metadata": {},
   "source": [
    "Стекинг (stacking) - это техника ансамблирования моделей, которая заключается в том, чтобы обучить несколько различных моделей и использовать их предсказания как новые признаки для обучения более высокоуровневой модели.\n",
    "\n",
    "В Python стекинг можно реализовать с помощью библиотеки scikit-learn. Вот пример реализации стекинга:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Загружаем данные\n",
    "data_train = pd.read_csv('train.csv')\n",
    "target_train = data_train['target']\n",
    "data_train.drop(['ID', 'target'], axis=1, inplace=True)\n",
    "X_train = data_train.values\n",
    "\n",
    "data_test = pd.read_csv('test.csv')\n",
    "data_test.drop(['ID'], axis=1, inplace=True)\n",
    "X_test = data_test.values\n",
    "\n",
    "# Определяем базовые модели\n",
    "models = [\n",
    "    ('KNN', KNeighborsRegressor(n_neighbors=7)),\n",
    "    ('DT', DecisionTreeRegressor(max_depth=5)),\n",
    "    ('RF', RandomForestRegressor(n_estimators=100, random_state=101)),\n",
    "    ('LR', LinearRegression()),\n",
    "    ('Ridge', Ridge(alpha=0.1)),\n",
    "    ('Lasso', Lasso(alpha=0.1))\n",
    "]\n",
    "\n",
    "# Создаем мета-модель\n",
    "meta_model = LinearRegression()\n",
    "\n",
    "# Функция для получения признаков, полученных от базовых моделей\n",
    "def get_base_models_features(X, models):\n",
    "    base_models_features = np.empty((X.shape[0], len(models)))\n",
    "    for i, (_, model) in enumerate(models):\n",
    "        base_models_features[:, i] = model.fit(X, target_train).predict(X)\n",
    "    return base_models_features\n",
    "\n",
    "# Получаем признаки, полученные от базовых моделей\n",
    "base_models_features_train = get_base_models_features(X_train, models)\n",
    "base_models_features_test = get_base_models_features(X_test, models)\n",
    "\n",
    "# Обучаем мета-модель и делаем предсказания\n",
    "meta_model.fit(base_models_features_train, target_train)\n",
    "predictions = meta_model.predict(base_models_features_test)\n",
    "```\n",
    "\n",
    "Этот пример показывает, как можно использовать шесть различных базовых моделей для предсказания целевой переменной. Затем эти базовые модели используются для получения новых признаков, которые используются для обучения более высокоуровневой мета-модели. Наконец, мы делаем предсказания с помощью мета-модели на тестовом наборе данных."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
